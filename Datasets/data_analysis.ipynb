{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "lexicon = Empath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully wrote all csv files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import argparse\n",
    "import json\n",
    "from util import contentToString, getSegments\n",
    "import csv\n",
    "from util import isGood\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dataset=\"PANC\"\n",
    "datapackID=None\n",
    "if datapackID is None: datapackID = dataset\n",
    "\n",
    "for datasetType in [\"train\", \"test\"]:\n",
    "\tdatapackPath = \"%s/datapacks/datapack-%s-%s.json\" % (\n",
    "\t\tdataset, datapackID, datasetType)\n",
    "\n",
    "\toutPath = os.path.join(\"%s/csv/\" % dataset)\n",
    "\tPath(outPath).mkdir(parents=True, exist_ok=True)\n",
    "\tcsvPath = os.path.join(outPath, \"%s-%s.csv\" %\n",
    "\t\t(datapackID, datasetType))\n",
    "\twith open(datapackPath, \"r\") as file:\n",
    "\t\tdatapack = json.load(file)\n",
    "\n",
    "\t\t# write TSV\n",
    "\t\t#with open(csvPath, 'w', newline='') as file:\n",
    "\t\t\t#writeCSV(file, datapack, datasetType)\n",
    "\n",
    "print(\"\\nSuccessfully wrote all csv files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_questions(body):\n",
    "    return body.count('?')\n",
    "    \n",
    "def size_of_words(body):\n",
    "    return np.mean([len(w) for w in body.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_based(body):\n",
    "    return lexicon.analyze(body, categories=[\"sexual\"])['sexual']\n",
    "\n",
    "def dictionary_based_multi(body, category):\n",
    "    return lexicon.analyze(body, categories=[category])[category]\n",
    "\n",
    "res = lexicon.analyze('Bro what')\n",
    "categories = list(res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_difference(x,y):\n",
    "    \"\"\"\n",
    "    Assume\n",
    "    x,y>=0\n",
    "    \"\"\"\n",
    "    absolute_difference = abs(x-y)\n",
    "    denom = max(x,y)\n",
    "    if denom > 0:\n",
    "        return absolute_difference/denom\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_metric(metric,absolute=False):\n",
    "    \"\"\"\n",
    "    Calulates the given metric for every message. Sums it up per author. Then the calculate the relative difference of this sum between the two authors.\n",
    "    Returns the average of these differences for non-predatory and predatory messages\n",
    "    \n",
    "    In other words, how many more \"metric\" does one author use compared to the other.\n",
    "    \n",
    "    The reason why we care about relative differences instead of absolute values is the assumption that predators talk diffrent that victims. We aim\n",
    "    to quantify this difference in writing style.\n",
    "    \n",
    "    For example calculate_metric(len) will return the average of the relative difference between the length of the messages of authorA and authorB\n",
    "    \"\"\"\n",
    "    rel_diff_pred = []\n",
    "    rel_diff_non = []\n",
    "    for chatName, chat in datapack[\"chats\"].items():\n",
    "        for i, segment in enumerate(getSegments(chat)):\n",
    "            #For every segment\n",
    "\n",
    "            len_dict = {} # Keys: authors, Values: sum of length of messages\n",
    "            for message in segment:\n",
    "                if message == None:\n",
    "                    continue\n",
    "\n",
    "                author = message[\"author\"]\n",
    "                body = message[\"body\"]\n",
    "\n",
    "                if body == None:\n",
    "                    continue\n",
    "\n",
    "                if author in len_dict.keys():\n",
    "                    len_dict[author] += metric(body)\n",
    "                else:\n",
    "                    len_dict[author] = metric(body)\n",
    "\n",
    "            # Some segments contain only one author. Maybe because of omegle\n",
    "            if len(len_dict.keys()) ==2 and segment[0]:\n",
    "                a, b = len_dict.values()\n",
    "                if not absolute:\n",
    "                    if (segment[0][\"isFromPredator\"]):\n",
    "                        rel_diff_pred.append(relative_difference(a,b))\n",
    "                    else:\n",
    "                        rel_diff_non.append(relative_difference(a,b))\n",
    "                else:\n",
    "                    if (segment[0][\"isFromPredator\"]):\n",
    "                        # in that case the variable souldn't be called rel_diff but anyway\n",
    "                        rel_diff_pred.append(a+b)\n",
    "                    else:\n",
    "                        rel_diff_non.append(a+b)\n",
    "    return np.mean(rel_diff_non), np.mean(rel_diff_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_multi(metric,category,absolute=False):\n",
    "    \"\"\"\n",
    "    Calulates the given metric for every message. Sums it up per author. Then the calculate the relative difference of this sum between the two authors.\n",
    "    Returns the average of these differences for non-predatory and predatory messages\n",
    "    \n",
    "    In other words, how many more \"metric\" does one author use compared to the other.\n",
    "    \n",
    "    The reason why we care about relative differences instead of absolute values is the assumption that predators talk diffrent that victims. We aim\n",
    "    to quantify this difference in writing style.\n",
    "    \n",
    "    For example calculate_metric(len) will return the average of the relative difference between the length of the messages of authorA and authorB\n",
    "    \"\"\"\n",
    "    rel_diff_pred = []\n",
    "    rel_diff_non = []\n",
    "    for chatName, chat in datapack[\"chats\"].items():\n",
    "        for i, segment in enumerate(getSegments(chat)):\n",
    "            #For every segment\n",
    "\n",
    "            len_dict = {} # Keys: authors, Values: sum of length of messages\n",
    "            for message in segment:\n",
    "                if message == None:\n",
    "                    continue\n",
    "\n",
    "                author = message[\"author\"]\n",
    "                body = message[\"body\"]\n",
    "\n",
    "                if body == None:\n",
    "                    continue\n",
    "\n",
    "                if author in len_dict.keys():\n",
    "                    len_dict[author] += metric(body,category)\n",
    "                else:\n",
    "                    len_dict[author] = metric(body,category)\n",
    "\n",
    "            # Some segments contain only one author. Maybe because of omegle\n",
    "            if len(len_dict.keys()) ==2 and segment[0]:\n",
    "                a, b = len_dict.values()\n",
    "                if not absolute:\n",
    "                    if (segment[0][\"isFromPredator\"]):\n",
    "                        rel_diff_pred.append(relative_difference(a,b))\n",
    "                    else:\n",
    "                        rel_diff_non.append(relative_difference(a,b))\n",
    "                else:\n",
    "                    if (segment[0][\"isFromPredator\"]):\n",
    "                        # in that case the variable souldn't be called rel_diff but anyway\n",
    "                        rel_diff_pred.append(a+b)\n",
    "                    else:\n",
    "                        rel_diff_non.append(a+b)\n",
    "    return np.mean(rel_diff_non), np.mean(rel_diff_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: (Non-predators, Predators)\n",
      "\n",
      "Difference in Message Length:  (0.4030566335339038, 0.38650301992468344)\n",
      "Absolute Message Length:  (1157.4328123772873, 3520.7461322081576)\n",
      "No. of questions:  (0.5738894152006618, 0.6764642266093621)\n"
     ]
    }
   ],
   "source": [
    "print(\"Metric: (Non-predators, Predators)\")\n",
    "print()\n",
    "print(\"Difference in Message Length: \", calculate_metric(len))\n",
    "print(\"Absolute Message Length: \", calculate_metric(len,absolute=True))\n",
    "print(\"No. of questions: \", calculate_metric(number_of_questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of words: (0.35141627101212997, 0.2416746686888594)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of words:\", calculate_metric(size_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary_based:  (0.22968258152114968, 0.5129049708592553)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary_based: \", calculate_metric(dictionary_based))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep  :  (0.13113417298524546, 0.4662130804442793)\n",
      "night  :  (0.11098099373458445, 0.4430081165995785)\n",
      "domestic_work  :  (0.11818739380970841, 0.44826138539994337)\n",
      "vacation  :  (0.17390972275210767, 0.4844983752458018)\n",
      "love  :  (0.19643064444230127, 0.5027391756238117)\n",
      "family  :  (0.20334340086697084, 0.5059048374817265)\n",
      "shopping  :  (0.12074464646325166, 0.4142074912117106)\n",
      "affection  :  (0.16251072556731427, 0.45149121500299955)\n",
      "furniture  :  (0.08436926651801388, 0.3733213640417662)\n",
      "body  :  (0.1665154620205998, 0.4541098162787639)\n",
      "home  :  (0.17952260777178475, 0.4666258821142494)\n",
      "celebration  :  (0.17253155232421707, 0.4567825306003938)\n",
      "sexual  :  (0.22968258152114968, 0.5129049708592553)\n",
      "work  :  (0.20446769712830343, 0.48592297526227196)\n",
      "morning  :  (0.08546836179954848, 0.36537593130420126)\n",
      "traveling  :  (0.19182767207742837, 0.46988756440197854)\n",
      "driving  :  (0.08261189232680631, 0.35599057822159086)\n",
      "shame  :  (0.15872840618241318, 0.43151336083825526)\n",
      "wedding  :  (0.13026411924157938, 0.4008250344748235)\n",
      "leisure  :  (0.16545639512906132, 0.43576125659748655)\n",
      "pain  :  (0.17841666163954192, 0.4469350242582623)\n",
      "surprise  :  (0.10154603178438881, 0.3687101322649845)\n",
      "toy  :  (0.15933791997072447, 0.4207845990546413)\n",
      "nervousness  :  (0.10440382860766902, 0.36499966229036446)\n",
      "strength  :  (0.18227522666359225, 0.44264631565450624)\n",
      "dispute  :  (0.17104939681905046, 0.43073608295127286)\n",
      "optimism  :  (0.2558165222836768, 0.5154298383902656)\n",
      "healing  :  (0.1304801869770848, 0.38993749452610216)\n",
      "injury  :  (0.12789021584278004, 0.38430143852084775)\n",
      "death  :  (0.12299666331905396, 0.37837788676396267)\n",
      "real_estate  :  (0.0690181680148695, 0.3215346577160923)\n",
      "contentment  :  (0.08836990532967005, 0.33975528690718565)\n",
      "business  :  (0.19951125829627475, 0.45070673011467133)\n",
      "weather  :  (0.24081957898749354, 0.49183255386712604)\n",
      "hygiene  :  (0.05746017888427558, 0.30607796641551915)\n",
      "vehicle  :  (0.061761266387041935, 0.30846694666648034)\n",
      "suffering  :  (0.1403616996888934, 0.3831544334708891)\n",
      "movement  :  (0.15444326980296508, 0.39692661201655205)\n",
      "play  :  (0.20518955637937814, 0.4461137739591657)\n",
      "emotional  :  (0.16803154523251906, 0.4072182691117291)\n",
      "cleaning  :  (0.10186465048975228, 0.3404367257215358)\n",
      "eating  :  (0.10877953885120203, 0.34731334783084594)\n",
      "confusion  :  (0.20161812388506803, 0.4392654208582478)\n",
      "fashion  :  (0.07156460715127172, 0.3063667872212176)\n",
      "clothing  :  (0.09298328703417842, 0.3252808767922023)\n",
      "cold  :  (0.2735726181269499, 0.5053925088338133)\n",
      "car  :  (0.05760553159241607, 0.288792511208123)\n",
      "feminine  :  (0.2699595207340859, 0.5009941800775005)\n",
      "trust  :  (0.1935018013043616, 0.4239067177733067)\n",
      "hate  :  (0.16750473493974632, 0.39543420082946024)\n",
      "restaurant  :  (0.08433299819669651, 0.31225858256448974)\n",
      "attractive  :  (0.2533607192099946, 0.479960383927471)\n",
      "sports  :  (0.15680865379286804, 0.3825563218231994)\n",
      "heroic  :  (0.12276645860836546, 0.3481817877387497)\n",
      "swearing_terms  :  (0.21838947399193875, 0.4432411402537528)\n",
      "party  :  (0.241163009490673, 0.4652629509019503)\n",
      "violence  :  (0.2267791463059978, 0.4484508434721968)\n",
      "fun  :  (0.21628377502918703, 0.4378136492569265)\n",
      "hearing  :  (0.2718579707697019, 0.49285682807411696)\n",
      "office  :  (0.11753364614041593, 0.3378094791596902)\n",
      "giving  :  (0.23711246918836396, 0.45596848611616536)\n",
      "money  :  (0.09224240248350828, 0.30957645066294853)\n",
      "meeting  :  (0.2702614770966224, 0.4862562950759055)\n",
      "ridicule  :  (0.07730568863059242, 0.29319224493275126)\n",
      "youth  :  (0.31198129848139744, 0.5273264833043607)\n",
      "shape_and_size  :  (0.1876863278375925, 0.3993561102669524)\n",
      "listen  :  (0.2865345055431762, 0.49391172001887157)\n",
      "messaging  :  (0.2777643161279243, 0.4843560081801581)\n",
      "cooking  :  (0.08518368803199557, 0.28885597505952754)\n",
      "social_media  :  (0.2513423324583302, 0.454701981414125)\n",
      "breaking  :  (0.09779519284349253, 0.30083718438148815)\n",
      "positive_emotion  :  (0.30410703029129327, 0.5062125162102374)\n",
      "warmth  :  (0.09457589322899933, 0.29577720490167747)\n",
      "order  :  (0.18481603067216704, 0.3840292295506935)\n",
      "children  :  (0.3261426184483814, 0.5245019012396924)\n",
      "childish  :  (0.26805224701718267, 0.46558545943076646)\n",
      "school  :  (0.15769630510854105, 0.3532416325665271)\n",
      "fabric  :  (0.053819979073257945, 0.24873616483871483)\n",
      "appearance  :  (0.21152958409556294, 0.4063376143419187)\n",
      "help  :  (0.14771076038325104, 0.34013972352849375)\n",
      "music  :  (0.17274770054289226, 0.3612588881781537)\n",
      "hipster  :  (0.1053621160901456, 0.2938069285379412)\n",
      "college  :  (0.1328175509142288, 0.32008911154480774)\n",
      "sound  :  (0.11148898811861194, 0.2952459343282128)\n",
      "computer  :  (0.21261156965718672, 0.3932867706601883)\n",
      "technology  :  (0.16671912321994783, 0.3456527805683924)\n",
      "fire  :  (0.09156466324847698, 0.26971457593820464)\n",
      "noise  :  (0.09462313387547032, 0.27081742683008503)\n",
      "timidity  :  (0.04029686641011544, 0.2162028665193222)\n",
      "competing  :  (0.0697125579203644, 0.24521158439934806)\n",
      "gain  :  (0.05935855650671484, 0.23238396624472574)\n",
      "phone  :  (0.31623394222374474, 0.48869704352891324)\n",
      "fear  :  (0.08998029118189332, 0.2599185800135167)\n",
      "prison  :  (0.0440351841671248, 0.20884903891233006)\n",
      "internet  :  (0.26449336842115445, 0.425465882375165)\n",
      "ocean  :  (0.06542448755203016, 0.2249053981648918)\n",
      "cheerfulness  :  (0.05010826760610787, 0.19947790137663554)\n",
      "rural  :  (0.09653394067907535, 0.24580235751121826)\n",
      "beach  :  (0.04940162981080282, 0.19831558502444574)\n",
      "pet  :  (0.0445409152347609, 0.19059339628959882)\n",
      "alcohol  :  (0.058709422596566245, 0.2034457578937185)\n",
      "swimming  :  (0.041157584529138765, 0.18357550794259656)\n",
      "sadness  :  (0.0649626205622436, 0.20658696671354898)\n",
      "water  :  (0.045586297390664, 0.18659231454590103)\n",
      "dominant_personality  :  (0.04900782743003743, 0.18992364878440826)\n",
      "divine  :  (0.09815024229726038, 0.23770173996967242)\n",
      "liquid  :  (0.049041763841889505, 0.1831920267574276)\n",
      "occupation  :  (0.07427288672478337, 0.20645413345835287)\n",
      "payment  :  (0.04728433429446545, 0.17906313486482262)\n",
      "weakness  :  (0.037704240574734565, 0.16938751590650325)\n",
      "medical_emergency  :  (0.05009461728616681, 0.18013696336481147)\n",
      "valuable  :  (0.05870248410890836, 0.1874916281561851)\n",
      "economics  :  (0.0735291312786797, 0.20121391735315786)\n",
      "friends  :  (0.40174214371379086, 0.5273295016585698)\n",
      "politeness  :  (0.23113321925070923, 0.356389289722623)\n",
      "deception  :  (0.0729982179787803, 0.1956868260665729)\n",
      "musical  :  (0.1343539738183577, 0.25494597070213326)\n",
      "animal  :  (0.07612150495995622, 0.19597857213890968)\n",
      "negative_emotion  :  (0.34750187810082966, 0.46716196530684007)\n",
      "art  :  (0.11958744698672445, 0.23864158969644203)\n",
      "sailing  :  (0.045129827631987376, 0.16178476547674858)\n",
      "air_travel  :  (0.04697636063771303, 0.16299505503092002)\n",
      "banking  :  (0.05624953464818382, 0.17002479080538152)\n",
      "weapon  :  (0.04855680589993006, 0.1592006563525551)\n",
      "fight  :  (0.06311720950062268, 0.17304043042439665)\n",
      "exercise  :  (0.05569720099877957, 0.16168932645725895)\n",
      "kill  :  (0.055105780630009, 0.15993905297702765)\n",
      "tool  :  (0.056483808476661686, 0.16066572902015938)\n",
      "smell  :  (0.03915416633943297, 0.14325675886857323)\n",
      "beauty  :  (0.07336560792541316, 0.17684013127051101)\n",
      "envy  :  (0.05015641770726982, 0.14958977965307077)\n",
      "lust  :  (0.052999330573350836, 0.15208626347866852)\n",
      "health  :  (0.04424367877992319, 0.14285630567276136)\n",
      "writing  :  (0.17325544260359307, 0.27153413276830995)\n",
      "dance  :  (0.08738448367169015, 0.18483555922901912)\n",
      "achievement  :  (0.09799761025905689, 0.1915427633782064)\n",
      "science  :  (0.09573334202643871, 0.18752539459290513)\n",
      "wealthy  :  (0.0383133938933829, 0.12864510079699953)\n",
      "reading  :  (0.154435883252411, 0.2430926707298015)\n",
      "plant  :  (0.04179028400805072, 0.13035630567276138)\n",
      "programming  :  (0.15194707166355637, 0.23972691045475855)\n",
      "stealing  :  (0.03521094994431993, 0.12154242850445383)\n",
      "aggression  :  (0.046752532788816456, 0.13291139240506328)\n",
      "communication  :  (0.4139958430377531, 0.4983848226641086)\n",
      "masculine  :  (0.2672889662149852, 0.3503071797437645)\n",
      "crime  :  (0.0521644086691601, 0.13448478385187246)\n",
      "royalty  :  (0.024056912484620017, 0.10618846694796062)\n",
      "white_collar_job  :  (0.039705227885546736, 0.11949132676980778)\n",
      "power  :  (0.044567920626194406, 0.11884669479606189)\n",
      "ugliness  :  (0.05094224605730142, 0.12241644899872747)\n",
      "horror  :  (0.023692374145920046, 0.0949367088607595)\n",
      "poor  :  (0.03933218147071913, 0.11052508204406938)\n",
      "war  :  (0.04245523754673208, 0.11278715424285043)\n",
      "anticipation  :  (0.014478688671730373, 0.08277074542897328)\n",
      "hiking  :  (0.03300620751535697, 0.10126414841604715)\n",
      "zest  :  (0.03540668603890155, 0.10344585091420534)\n",
      "urban  :  (0.030629074059530356, 0.09815986872948897)\n",
      "joy  :  (0.029464122097437102, 0.09664791373652133)\n",
      "tourism  :  (0.0509637499859757, 0.11807815953385573)\n",
      "leader  :  (0.05940731432760019, 0.1252344116268167)\n",
      "speaking  :  (0.42063407428778543, 0.483707736121885)\n",
      "blue_collar_job  :  (0.025071336945993353, 0.0874355368026254)\n",
      "sympathy  :  (0.03077043901672819, 0.09184247538677918)\n",
      "farming  :  (0.019683449703869087, 0.07385138302859821)\n",
      "ship  :  (0.02194952747454122, 0.07610006027727548)\n",
      "ancient  :  (0.1943520087162591, 0.24734545420199427)\n",
      "worship  :  (0.03629411026332411, 0.08820574643359454)\n",
      "anonymity  :  (0.015052750071991415, 0.06604547585560243)\n",
      "torment  :  (0.018717767480824102, 0.06786216596343178)\n",
      "law  :  (0.03965025262441425, 0.08878340365682137)\n",
      "journalism  :  (0.08202788903723482, 0.12872714486638537)\n",
      "anger  :  (0.018228225869787167, 0.060829817158931085)\n",
      "exotic  :  (0.018495248566716405, 0.05916549460853258)\n",
      "magic  :  (0.03455999222118753, 0.06358415377402718)\n",
      "military  :  (0.027755962197963294, 0.05119549929676512)\n",
      "legend  :  (0.028077960156025025, 0.05086732301922175)\n",
      "religion  :  (0.01487090163168071, 0.03563893911995178)\n",
      "negotiate  :  (0.019791094007696537, 0.038326300984528834)\n",
      "irritability  :  (0.011427000706824786, 0.02461322081575246)\n",
      "medieval  :  (0.010688761485902773, 0.022269104547585558)\n",
      "neglect  :  (0.01146626875049085, 0.022151898734177215)\n",
      "pride  :  (0.014895677897327155, 0.02531645569620253)\n",
      "monster  :  (0.016126076598863844, 0.026254102203469288)\n",
      "politics  :  (0.014640435613497732, 0.006329113924050633)\n",
      "disappointment  :  (0.01657111442707924, 0.02461322081575246)\n",
      "superhero  :  (0.012016021361815754, 0.01828410689170183)\n",
      "exasperation  :  (0.0052619178512526505, 0.011251758087201125)\n",
      "rage  :  (0.009928270373569989, 0.014064697609001406)\n",
      "philosophy  :  (0.024238854420272783, 0.02707454289732771)\n",
      "independence  :  (0.009699206785517946, 0.007032348804500703)\n",
      "dominant_heirarchical  :  (0.015746485510091886, 0.01810829817158931)\n",
      "government  :  (0.03884841957173694, 0.04043600562587905)\n",
      "disgust  :  (0.014450640069111757, 0.014767932489451477)\n",
      "terrorism  :  (0.009920773747051921, 0.009845288326300985)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "with open('category_scores.pickle', 'wb') as handle:\n",
    "    pickle.dump(category_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\"\n",
    "\n",
    "with open('category_scores.pickle', 'rb') as handle:\n",
    "    category_score = pickle.load(handle)\n",
    "for key, value in category_score.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncategory_scores = {}\\nfor category in categories:\\n    res = calculate_metric_multi(dictionary_based_multi,category)\\n    print(category,\": \", res)\\n    category_scores[category] = res\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "category_scores = {}\n",
    "for category in categories:\n",
    "    res = calculate_metric_multi(dictionary_based_multi,category)\n",
    "    print(category,\": \", res)\n",
    "    category_scores[category] = res\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try emotion bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/bert-base-go-emotion\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bhadresh-savani/bert-base-go-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      5\u001b[0m     args\u001b[38;5;241m=\u001b[39mTrainingArguments(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./predictions\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#eval_dataset=test_data,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m tokenizer([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi like it and I love it\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2532\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2529\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2531\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2532\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2535\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   2536\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   2537\u001b[0m     speed_metrics(\n\u001b[1;32m   2538\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2542\u001b[0m     )\n\u001b[1;32m   2543\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2625\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2623\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 2625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:238\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encodings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with integers (to access backend Encoding for a given batch index) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not available when using Python based tokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#model.predict(tokenized)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir='./predictions'),\n",
    "    #eval_dataset=test_data,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "tokenized = tokenizer(\"i like it and I love it\")\n",
    "trainer.predict(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
